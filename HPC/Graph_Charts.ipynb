{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracies of NN Models in Image Classification\n",
    "\n",
    "Acc_inc = 0.4346 \n",
    "Acc_res = 0.3070 \n",
    "Acc_vgg16 = 0.7064 \n",
    "Acc_vgg19 = 0.5843 \n",
    "Acc_Mobile = 0.7634 \n",
    "Acc_cnn = 0.8318 \n",
    "\n",
    "Acc =[]\n",
    "label = []\n",
    "\n",
    "Acc = [Acc_inc, Acc_res, Acc_vgg16,Acc_cnn, Acc_vgg19, Acc_Mobile ]\n",
    "label = ['InceptionV3','Resnet50','VGG16','CNN','VGG19','Mobilenet']\n",
    "\n",
    "x_axis = np.arange(len(Acc))\n",
    "y_axis = Acc\n",
    "\n",
    "plt.bar(x_axis, y_axis, color=['coral', 'coral', 'coral','deepskyblue', 'coral', 'coral' ])\n",
    "plt.xticks(x_axis, label, fontsize=10, rotation=30)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Comparison Between All Algorithms\")\n",
    "\n",
    "plt.savefig('Graphs/fig2.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#latency time for training neural networks for image classification\n",
    "\n",
    "Time_inc = 134.13 \n",
    "Time_res = 112.75 \n",
    "Time_vgg16 = 46.18 \n",
    "Time_vgg19 = 242.6\n",
    "Time_Mobile = 345.41\n",
    "Time_cnn = 30.11\n",
    "\n",
    "time =[]\n",
    "time = [Time_inc, Time_res, Time_vgg16, Time_vgg19, Time_Mobile, Time_cnn]\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(time))\n",
    "y_axis = time\n",
    "\n",
    "plt.plot( x_axis, y_axis, marker='o', markerfacecolor='indigo', markersize=8, color='plum', linewidth=3)\n",
    "\n",
    "\n",
    "plt.xticks(x_axis, label, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time\")\n",
    "plt.title(\"Latency Time measured in MINUTES\")\n",
    "\n",
    "plt.savefig(\"Graphs/fig3.png\",bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Feature Extraction for neural networks\n",
    "\n",
    "Feature_inc = 4871.101/60\n",
    "Feature_res = 10320.901/60\n",
    "Feature_vgg16 = 5190.0866/60\n",
    "Feature_vgg19 = 5976.152/60\n",
    "Feature_Mobile = 1572.2566/60\n",
    "\n",
    "\n",
    "Pre_Feature_Time = []\n",
    "\n",
    "Pre_Feature_Time = [Feature_inc, Feature_res, Feature_vgg16, Feature_vgg19, Feature_Mobile]\n",
    "Pre_Label_Fea = ['InceptionV3','Resnet50','VGG16','VGG19','Mobilenet']\n",
    "x_axis = np.arange(len(Pre_Feature_Time))\n",
    "\n",
    "\n",
    "plt.plot( x_axis, Pre_Feature_Time, marker='o', markerfacecolor='darkcyan', markersize=8, color='lightblue', linewidth=3)\n",
    "\n",
    "plt.xticks(x_axis, Pre_Label_Fea, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time in MINUTES\")\n",
    "plt.title('Latency Time for Neural Networks')\n",
    "\n",
    "plt.savefig('Graphs/fig4.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Feature Extraction for computer vision\n",
    "\n",
    "Feature_Kaze = 959.240/60\n",
    "Feature_SIFT = 197.399/60\n",
    "Feature_SURF = 131.219/60\n",
    "\n",
    "Feature_Time = []\n",
    "\n",
    "Feature_Time = [Feature_Kaze, Feature_SIFT, Feature_SURF]\n",
    "Label_Fea = ['KAZE','SIFT','SURF']\n",
    "x_axis = np.arange(len(Feature_Time))\n",
    "\n",
    "plt.plot( x_axis, Feature_Time, marker='o', markerfacecolor='darkgoldenrod', markersize=8, color='khaki', linewidth=3)\n",
    "\n",
    "\n",
    "plt.xticks(x_axis, Label_Fea, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time in MINUTES\")\n",
    "plt.title('Latency Time for Computer Vision')\n",
    "\n",
    "plt.savefig('Graphs/fig5.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Average Precision for Baseline-1\n",
    "\n",
    "Inceptionv3 = 0.625\n",
    "MobileNet = 0.70\n",
    "Vgg16 =  0.617\n",
    "Vgg19 = 0.669\n",
    "ResNet = 0.65\n",
    "\n",
    "Pre_Avg_Precision = []\n",
    "\n",
    "\n",
    "Pre_Avg_Precision = [Inceptionv3, Vgg16, MobileNet, ResNet, Vgg19 ]\n",
    "Pre_Label_Fea = ['InceptionV3','VGG16','Mobilenet','Resnet50','VGG19']\n",
    "x_axis = np.arange(len(Pre_Avg_Precision))\n",
    "\n",
    "plt.plot( x_axis, Pre_Avg_Precision, marker='o', markerfacecolor='blue', markersize=8, color='skyblue', linewidth=4, label=\"Pre_Avg_Precision\")\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(x_axis, Pre_Label_Fea, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Average Precision@k\")\n",
    "plt.title('Average Precision@k (Baseline-1)')\n",
    "\n",
    "plt.savefig('Graphs/fig6.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Average Precision for Baseline-2\n",
    "\n",
    "surf_precision = 0.533\n",
    "surf_recall = 0.361\n",
    "\n",
    "sift_precision = 0.461\n",
    "sift_recall = 0.4\n",
    "\n",
    "kaze_precision = 0.415\n",
    "kaze_recall = 0.506\n",
    "\n",
    "\n",
    "Avg_Precision = []\n",
    "Avg_Recall = []\n",
    "\n",
    "\n",
    "Avg_Precision = [kaze_precision , surf_precision, sift_precision]\n",
    "#Avg_Recall = [surf_recall, sift_recall, kaze_recall]\n",
    "\n",
    "Labels = ['KAZE', 'SURF','SIFT']\n",
    "x_axis = np.arange(len(Avg_Precision))\n",
    "\n",
    "\n",
    "plt.plot( x_axis, Avg_Precision, marker='o', markerfacecolor='green', markersize=8, color='green', linewidth=3, label=\"Avg_Precision\")\n",
    "#plt.plot( x_axis, Avg_Recall, marker='o', markerfacecolor='orange', markersize=8, color='orange', linewidth=3, label=\"Avg_Recall\")\n",
    "\n",
    "#plt.legend()\n",
    "\n",
    "plt.xticks(x_axis, Labels, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Average Precision@k\")\n",
    "\n",
    "plt.title('Average Precision@k(Baseline-2)')\n",
    "\n",
    "plt.savefig('Graphs/fig7.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transfer Learning Mobilenet\n",
    "#BarChart to compare different Accuracies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [0.7456612806702573, 0.5499700777977259, 0.8456014362657092, 0.7073608617594255, 0.7564332734889287,  0.7959305804907241, 0.6792339916217833]\n",
    "label = ['RF','DT','SGD','KNN','EXT','GDB','NaiveBayes']\n",
    "\n",
    "x_axis = np.arange(len(F1Score))\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis,  color=['lavender', 'lavender', 'lightsalmon', 'lavender', 'lavender', 'lavender','lavender'])\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison - MobileNet features')\n",
    "plt.savefig('Graphs/Mobile_Net_F1_Score.png', bbox_inches=\"tight\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time comparison\n",
    "label = ['RF','DT','SGD','KNN','EXT','GDB','NaiveBayes']\n",
    "TimeComparison = [33.21971293488863, 93.85094023113408, 96.16421558831826,  924.2772161510852, 246.3643326783922, 5741.348179324952, 29881.421007406694] \n",
    "\n",
    "\n",
    "x_axis = np.arange(len(TimeComparison))\n",
    "plt.plot( x_axis, TimeComparison, marker='o', markerfacecolor='indigo', markersize=8, color='plum', linewidth=3)\n",
    "\n",
    "plt.xticks(x_axis, label, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time in SECONDS\")\n",
    "plt.title('Latency Time for MobileNet features')\n",
    "plt.savefig('Graphs/Mobile_Net_Latency.png', bbox_inches=\"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tranfer Learning\n",
    "# VGG 19 Features\n",
    "\n",
    "#BarChart to compare different Accuracies\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [0.751047277079593, 0.5966487133453022, 0.8288450029922202, 0.49251944943147813, 0.7666068222621186, 0.7911430281268701, 0.6552962298025135]\n",
    "label = ['RF','DT','SGD','KNN','EXT','GDB','NaiveBayes']\n",
    " \n",
    "\n",
    "x_axis = np.arange(len(F1Score))\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis,color=['paleturquoise', 'paleturquoise', 'lightsalmon', 'paleturquoise', 'paleturquoise', 'paleturquoise','paleturquoise'])\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison - VGG19 features')\n",
    "\n",
    "plt.savefig('Graphs/VGG19_Feature_F1_Score.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Latency Time VGG 19\n",
    "\n",
    "TimeComparison = [18.11999999999999, 33.33000000000001, 6.849999999998545, 418.96000000000004 , 1076.5700000000002, 1783.41, 5.020000000000437] \n",
    "\n",
    "x_axis = np.arange(len(TimeComparison))\n",
    "\n",
    "plt.plot( x_axis, TimeComparison, marker='o', markerfacecolor='lightseagreen', markersize=8, color='paleturquoise', linewidth=3)\n",
    "\n",
    "plt.xticks(x_axis, label, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time in SECONDS\")\n",
    "plt.title('Latency Time for VGG19 Features')\n",
    "\n",
    "plt.savefig('Graphs/VGG19_Feature_Latency.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tranfer Learning\n",
    "# VGG 16\n",
    "\n",
    "#BarChart to compare different F1Scores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [0.7432675044883303, 0.5840813883901855, 0.824655894673848, 0.4506283662477558, 0.7522441651705565, 0.7911430281268701, 0.6499102333931778]\n",
    "label = ['RF','DT','SGD','KNN','EXT','GDB','NaiveBayes']\n",
    "\n",
    "x_axis = np.arange(len(F1Score))\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis, color=['thistle', 'thistle', 'lightsalmon', 'thistle', 'thistle', 'thistle','thistle'])\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison - VGG16 features')\n",
    "\n",
    "plt.savefig('Graphs/VGG16_Feature_F1_Score.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Latency Time VGG 16\n",
    "TimeComparison = [18.029999999999987, 31.260000000000005, 5.9500000000000455, 408.5400000000002, 676.29,  1783.41, 52.60806541757847] \n",
    "\n",
    "x_axis = np.arange(len(TimeComparison))\n",
    "\n",
    "plt.plot( x_axis, TimeComparison, marker='o', markerfacecolor='seagreen', markersize=8, color='aquamarine', linewidth=3)\n",
    "\n",
    "plt.xticks(x_axis, label, fontsize=10, rotation=30)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time in SECONDS\")\n",
    "plt.title('Latency Time for VGG16 Features')\n",
    "plt.savefig('Graphs/VGG16_Feature_Latency.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Final Bar Chart for report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [0.70, 0.749, 0.749]\n",
    "label = ['Baseline','Enhanced Kmeans','Enhanced Cosine']\n",
    "\n",
    "x_axis = np.arange(len(F1Score))\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis, color = ['seagreen','seagreen','crimson'],width = 0.3)\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('Average Precision: Baseline vs Enhanced')\n",
    "plt.savefig('Graphs/Final_Result_Bar1.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Latency Time \n",
    "\n",
    "TimeComparison = [11.58,240,12.83] \n",
    "\n",
    "x_axis = np.arange(len(TimeComparison))\n",
    "\n",
    "plt.plot( x_axis, TimeComparison, marker='o', markerfacecolor='purple', markersize=8, color='salmon', linewidth=3)\n",
    "\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Latency Time in SECONDS\")\n",
    "plt.title('Latency Time: Baseline vs Enhanced')\n",
    "plt.savefig('Graphs/lat_be.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cosine vs kmeans For PPT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [0.749, 0.749]\n",
    "label = ['Kmeans','Cosine']\n",
    "\n",
    "x_axis = [0.5,1.0]\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis, color = ['coral','coral'],width = 0.3)\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('Average Precision With and Without Kmeans')\n",
    "plt.savefig('Graphs/Final_Bar1.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cosine vs kmeans For PPT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "F1Score =[]\n",
    "label = []\n",
    "\n",
    "F1Score = [0.70, 0.749]\n",
    "label = ['Baseline','Cosine']\n",
    "\n",
    "x_axis = [0.5,1.0]\n",
    "y_axis = F1Score\n",
    "\n",
    "plt.bar(x_axis, y_axis, color = ['purple','purple'],width = 0.3)\n",
    "plt.xticks(x_axis, label, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Average Precision')\n",
    "plt.title('Average Precision Between Baseline and Enhanced')\n",
    "plt.savefig('Graphs/Final_Bar2.png',bbox_inches = \"tight\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Final - Latency time - Bar 1 (PPT)\n",
    "\n",
    "Avg_Precision = [240,12.83]\n",
    "\n",
    "\n",
    "Labels = ['Enhanced Kmeans','Enhanced Cosine']\n",
    "x_axis = np.arange(len(Avg_Precision))\n",
    "\n",
    "\n",
    "plt.plot( x_axis, Avg_Precision, marker='o', markerfacecolor='purple', markersize=8, color='violet', linewidth=3, label=\"Avg_Precision\")\n",
    "\n",
    "plt.xticks(x_axis, Labels, fontsize=10)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Latency Time')\n",
    "plt.title('Latency Time With and Without Kmeans')\n",
    "\n",
    "plt.savefig('Graphs/Bar1_lat1.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Final - Latency time - Bar 2 (PPT)\n",
    "\n",
    "Avg_Precision = [11.58,12.83]\n",
    "\n",
    "\n",
    "Labels = ['Baseline','Enhanced']\n",
    "x_axis = np.arange(len(Avg_Precision))\n",
    "\n",
    "\n",
    "plt.plot( x_axis, Avg_Precision, marker='o', markerfacecolor='green', markersize=8, color='limegreen', linewidth=3, label=\"Avg_Precision\")\n",
    "\n",
    "plt.xticks(x_axis, Labels, fontsize=10)\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel('Latency Time')\n",
    "plt.title('Latency Time Comparison Between Baseline and Enhanced')\n",
    "\n",
    "plt.savefig('Graphs/Bar2_lat2.png',bbox_inches = \"tight\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
